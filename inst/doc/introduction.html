<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Zena Lapp" />


<title>Introduction to mikropml</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">

div.csl-bib-body { }
div.csl-entry {
clear: both;
}
.hanging div.csl-entry {
margin-left:2em;
text-indent:-2em;
}
div.csl-left-margin {
min-width:2em;
float:left;
}
div.csl-right-inline {
margin-left:2em;
padding-left:1em;
}
div.csl-indent {
margin-left: 2em;
}
</style>

<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Introduction to mikropml</h1>
<h4 class="author">Zena Lapp</h4>



<p>The goal of <code>mikropml</code> is to make supervised machine
learning (ML) easy for you to run while implementing good practices for
machine learning pipelines. All you need to run the ML pipeline is one
function: <code>run_ml()</code>. We’ve selected sensible default
arguments related to good practices <span class="citation">(Topçuoğlu et
al. 2020; Tang et al. 2020)</span>, but we allow you to change those
arguments to tailor <code>run_ml()</code> to the needs of your data.</p>
<p>This document takes you through all of the <code>run_ml()</code>
inputs, both required and optional, as well as the outputs.</p>
<p>In summary, you provide:</p>
<ul>
<li>A dataset with an outcome column and feature columns (rows are
samples; unfortunately we do not support multi-label
classification)</li>
<li>Model choice (i.e. method)</li>
</ul>
<p>And the function outputs:</p>
<ul>
<li>The trained model</li>
<li>Model performance metrics</li>
<li>(Optional) feature importance metrics</li>
</ul>
<div id="its-running-so-slow" class="section level1">
<h1>It’s running so slow!</h1>
<p>Since I assume a lot of you won’t read this entire vignette, I’m
going to say this at the beginning. If the <code>run_ml()</code>
function is running super slow, you should consider parallelizing. See
<code>vignette(&quot;parallel&quot;)</code> for examples.</p>
</div>
<div id="understanding-the-inputs" class="section level1">
<h1>Understanding the inputs</h1>
<div id="the-input-data" class="section level2">
<h2>The input data</h2>
<p>The input data to <code>run_ml()</code> is a dataframe where each row
is a sample or observation. One column (assumed to be the first) is the
outcome of interest, and all of the other columns are the features. We
package <code>otu_mini_bin</code> as a small example dataset with
<code>mikropml</code>.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="co"># install.packages(&quot;devtools&quot;)</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="co"># devtools::install_github(&quot;SchlossLab/mikropml&quot;)</span></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="fu">library</span>(mikropml)</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="fu">head</span>(otu_mini_bin)</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="co">#&gt;       dx Otu00001 Otu00002 Otu00003 Otu00004 Otu00005 Otu00006 Otu00007</span></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="co">#&gt; 1 normal      350      268      213        1      208      230       70</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="co">#&gt; 2 normal      568     1320       13      293      671      103       48</span></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="co">#&gt; 3 normal      151      756      802      556      145      271       57</span></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="co">#&gt; 4 normal      299       30     1018        0       25       99       75</span></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a><span class="co">#&gt; 5 normal     1409      174        0        3        2     1136      296</span></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="co">#&gt; 6 normal      167      712      213        4      332      534      139</span></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a><span class="co">#&gt;   Otu00008 Otu00009 Otu00010</span></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a><span class="co">#&gt; 1      230      235       64</span></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a><span class="co">#&gt; 2      204      119      115</span></span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a><span class="co">#&gt; 3      176       37      710</span></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a><span class="co">#&gt; 4       78      255      197</span></span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a><span class="co">#&gt; 5        1      537      533</span></span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a><span class="co">#&gt; 6      251      155      122</span></span></code></pre></div>
<p>Here, <code>dx</code> is the outcome column (normal or cancer), and
there are 10 features (<code>Otu00001</code> through
<code>Otu00010</code>). Because there are only 2 outcomes, we will be
performing binary classification in the majority of the examples below.
At the bottom, we will also briefly provide examples of multi-class and
continuous outcomes. As you’ll see, you run them in the same way as for
binary classification!</p>
<p>The feature columns are the amount of each <a href="https://en.wikipedia.org/wiki/Operational_taxonomic_unit">Operational
Taxonomic Unit (OTU)</a> in microbiome samples from patients with cancer
and without cancer. The goal is to predict <code>dx</code>, which stands
for diagnosis. This diagnosis can be cancer or not based on an
individual’s microbiome. No need to understand exactly what that means,
but if you’re interested you can read more about it from the original
paper <span class="citation">(Topçuoğlu et al. 2020)</span>.</p>
<p>For real machine learning applications you’ll need to use more
features, but for the purposes of this vignette we’ll stick with this
example dataset so everything runs faster.</p>
</div>
<div id="the-methods-we-support" class="section level2">
<h2>The methods we support</h2>
<p>All of the methods we use are supported by a great ML wrapper package
<a href="https://topepo.github.io/caret/"><code>caret</code></a>, which
we use to train our machine learning models.</p>
<p>The methods we have tested (and their backend packages) are:</p>
<ul>
<li>Logistic/multiclass/linear regression (<code>&quot;glmnet&quot;</code>)</li>
<li>Random forest (<code>&quot;rf&quot;</code>)</li>
<li>Decision tree (<code>&quot;rpart2&quot;</code>)</li>
<li>Support vector machine with a radial basis kernel
(<code>&quot;svmRadial&quot;</code>)</li>
<li>xgboost (<code>&quot;xgbTree&quot;</code>)</li>
</ul>
<p>For documentation on these methods, as well as many others, you can
look at the <a href="https://topepo.github.io/caret/available-models.html">available
models</a> (or see <a href="https://topepo.github.io/caret/train-models-by-tag.html">here</a>
for a list by tag). While we have not vetted the other models used by
<code>caret</code>, our function is general enough that others might
work. While we can’t promise that we can help with other models, feel
free to [start a new discussion on GitHub]<a href="https://github.com/SchlossLab/mikropml/discussions" class="uri">https://github.com/SchlossLab/mikropml/discussions</a>) if
you have questions about other models and we <em>might</em> be able to
help.</p>
<p>We will first focus on <code>glmnet</code>, which is our default
implementation of L2-regularized logistic regression. Then we will cover
a few other examples towards the end.</p>
</div>
</div>
<div id="before-running-ml" class="section level1">
<h1>Before running ML</h1>
<p>Before you execute <code>run_ml()</code>, you should consider
preprocessing your data, either on your own or with the
<code>preprocess_data()</code> function. You can learn more about this
in the preprocessing vignette: <code>vignette(&quot;preprocess&quot;)</code>.</p>
</div>
<div id="the-simplest-way-to-run_ml" class="section level1">
<h1>The simplest way to <code>run_ml()</code></h1>
<p>As mentioned above, the minimal input is your dataset
(<code>dataset</code>) and the machine learning model you want to use
(<code>method</code>).</p>
<p>You may also want to provide:</p>
<ul>
<li>The outcome column name. By default <code>run_ml()</code> will pick
the first column, but it’s best practice to specify the column name
explicitly.</li>
<li>A seed so that the results will be reproducible, and so that you get
the same results as those you see here (i.e have the same train/test
split).</li>
</ul>
<p>Say we want to use logistic regression, then the method we will use
is <code>glmnet</code>. To do so, run the ML pipeline with:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">run_ml</span>(otu_mini_bin,</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>  <span class="st">&quot;glmnet&quot;</span>,</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>  <span class="at">outcome_colname =</span> <span class="st">&quot;dx&quot;</span>,</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">2019</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>)</span></code></pre></div>
<p>You’ll notice a few things:</p>
<ol style="list-style-type: decimal">
<li>It takes a little while to run. This is because of some of the
parameters we use.</li>
<li>There is a message stating that ‘dx’ is being used as the outcome
column. This is what we want, but it’s a nice sanity check!</li>
<li>There was a warning. Don’t worry about this warning right now - it
just means that some of the hyperparameters aren’t a good fit - but if
you’re interested in learning more, see
<code>vignette(&quot;tuning&quot;)</code>.</li>
</ol>
<p>Now, let’s dig into the output a bit. The results is a list of 4
things:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="fu">names</span>(results)</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="co">#&gt; [1] &quot;trained_model&quot;      &quot;test_data&quot;          &quot;performance&quot;       </span></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="co">#&gt; [4] &quot;feature_importance&quot;</span></span></code></pre></div>
<p><code>trained_model</code> is the trained model from
<code>caret</code>. There is a bunch of info in this that we won’t get
into, because you can learn more from the <code>caret::train()</code>
documentation.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="fu">names</span>(results<span class="sc">$</span>trained_model)</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="co">#&gt;  [1] &quot;method&quot;       &quot;modelInfo&quot;    &quot;modelType&quot;    &quot;results&quot;      &quot;pred&quot;        </span></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a><span class="co">#&gt;  [6] &quot;bestTune&quot;     &quot;call&quot;         &quot;dots&quot;         &quot;metric&quot;       &quot;control&quot;     </span></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a><span class="co">#&gt; [11] &quot;finalModel&quot;   &quot;preProcess&quot;   &quot;trainingData&quot; &quot;ptype&quot;        &quot;resample&quot;    </span></span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a><span class="co">#&gt; [16] &quot;resampledCM&quot;  &quot;perfNames&quot;    &quot;maximize&quot;     &quot;yLimits&quot;      &quot;times&quot;       </span></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="co">#&gt; [21] &quot;levels&quot;</span></span></code></pre></div>
<p><code>test_data</code> is the partition of the dataset that was used
for testing. In machine learning, it’s always important to have a
held-out test dataset that is not used in the training stage. In this
pipeline we do that using <code>run_ml()</code> where we split your data
into training and testing sets. The training data are used to build the
model (e.g. tune hyperparameters, learn the data) and the test data are
used to evaluate how well the model performs.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="fu">head</span>(results<span class="sc">$</span>test_data)</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="co">#&gt;        dx Otu00009 Otu00005 Otu00010 Otu00001 Otu00008 Otu00004 Otu00003</span></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="co">#&gt; 9  normal      119      142      248      256      363      112      871</span></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a><span class="co">#&gt; 14 normal       60      209       70       86       96        1      123</span></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a><span class="co">#&gt; 16 cancer      205        5      180     1668       95       22        3</span></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a><span class="co">#&gt; 17 normal      188      356      107      381     1035      915      315</span></span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a><span class="co">#&gt; 27 normal        4       21      161        7        1       27        8</span></span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a><span class="co">#&gt; 30 normal       13      166        5       31       33        5       58</span></span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a><span class="co">#&gt;    Otu00002 Otu00007 Otu00006</span></span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a><span class="co">#&gt; 9       995        0      137</span></span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a><span class="co">#&gt; 14      426       54       40</span></span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a><span class="co">#&gt; 16       20      590      570</span></span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a><span class="co">#&gt; 17      357      253      341</span></span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a><span class="co">#&gt; 27       25      322        5</span></span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a><span class="co">#&gt; 30      179        6       30</span></span></code></pre></div>
<p><code>performance</code> is a dataframe of (mainly) performance
metrics (1 column for cross-validation performance metric, several for
test performance metrics, and 2 columns at the end with ML method and
seed):</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>results<span class="sc">$</span>performance</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 × 17</span></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a><span class="co">#&gt;   cv_metric_AUC logLoss   AUC prAUC Accuracy Kappa    F1 Sensitivity Specificity</span></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a><span class="co">#&gt;           &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;</span></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a><span class="co">#&gt; 1         0.622   0.684 0.647 0.606    0.590 0.179   0.6         0.6       0.579</span></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a><span class="co">#&gt; # ℹ 8 more variables: Pos_Pred_Value &lt;dbl&gt;, Neg_Pred_Value &lt;dbl&gt;,</span></span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a><span class="co">#&gt; #   Precision &lt;dbl&gt;, Recall &lt;dbl&gt;, Detection_Rate &lt;dbl&gt;,</span></span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a><span class="co">#&gt; #   Balanced_Accuracy &lt;dbl&gt;, method &lt;chr&gt;, seed &lt;dbl&gt;</span></span></code></pre></div>
<p>When using logistic regression for binary classification, area under
the receiver-operator characteristic curve (AUC) is a useful metric to
evaluate model performance. Because of that, it’s the default that we
use for <code>mikropml</code>. However, it is crucial to evaluate your
model performance using multiple metrics. Below you can find more
information about other performance metrics and how to use them in our
package.</p>
<p><code>cv_metric_AUC</code> is the AUC for the cross-validation folds
for the training data. This gives us a sense of how well the model
performs on the training data.</p>
<p>Most of the other columns are performance metrics for the test data —
the data that wasn’t used to build the model. Here, you can see that the
AUC for the test data is not much above 0.5, suggesting that this model
does not predict much better than chance, and that the model is overfit
because the cross-validation AUC (<code>cv_metric_AUC</code>, measured
during training) is much higher than the testing AUC. This isn’t too
surprising since we’re using so few features with this example dataset,
so don’t be discouraged. The default option also provides a number of
other performance metrics that you might be interested in, including
area under the precision-recall curve (prAUC).</p>
<p>The last columns of <code>results$performance</code> are the method
and seed (if you set one) to help with combining results from multiple
runs (see <code>vignette(&quot;parallel&quot;)</code>).</p>
<p><code>feature_importance</code> has information about feature
importance values if <code>find_feature_importance = TRUE</code> (the
default is <code>FALSE</code>). Since we used the defaults, there’s
nothing here:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>results<span class="sc">$</span>feature_importance</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="co">#&gt; [1] &quot;Skipped feature importance&quot;</span></span></code></pre></div>
</div>
<div id="customizing-parameters" class="section level1">
<h1>Customizing parameters</h1>
<p>There are a few arguments that allow you to change how you execute
<code>run_ml()</code>. We’ve chosen reasonable defaults for you, but we
encourage you to change these if you think something else would be
better for your data.</p>
<div id="changing-kfold-cv_times-and-training_frac" class="section level2">
<h2>Changing <code>kfold</code>, <code>cv_times</code>, and
<code>training_frac</code></h2>
<ul>
<li><code>kfold</code>: The number of folds to run for cross-validation
(default: 5).</li>
<li><code>cv_times</code>: The number of times to run repeated
cross-validation (default: 100).</li>
<li><code>training_frac</code>: The fraction of data for the training
set (default: 0.8). The rest of the data is used for testing.</li>
</ul>
<p>Here’s an example where we change some of the default parameters:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>results_custom <span class="ot">&lt;-</span> <span class="fu">run_ml</span>(otu_mini_bin,</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>  <span class="st">&quot;glmnet&quot;</span>,</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>  <span class="at">kfold =</span> <span class="dv">2</span>,</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>  <span class="at">cv_times =</span> <span class="dv">5</span>,</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a>  <span class="at">training_frac =</span> <span class="fl">0.5</span>,</span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">2019</span></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a>)</span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a><span class="co">#&gt; Using &#39;dx&#39; as the outcome column.</span></span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a><span class="co">#&gt; Training the model...</span></span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a><span class="co">#&gt; Loading required package: ggplot2</span></span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a><span class="co">#&gt; Loading required package: lattice</span></span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a><span class="co">#&gt; Attaching package: &#39;caret&#39;</span></span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a><span class="co">#&gt; The following object is masked from &#39;package:mikropml&#39;:</span></span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a><span class="co">#&gt;     compare_models</span></span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a><span class="co">#&gt; Warning in (function (w) : `caret::train()` issued the following warning:</span></span>
<span id="cb8-18"><a href="#cb8-18" tabindex="-1"></a><span class="co">#&gt;  </span></span>
<span id="cb8-19"><a href="#cb8-19" tabindex="-1"></a><span class="co">#&gt; simpleWarning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : There were missing values in resampled performance measures.</span></span>
<span id="cb8-20"><a href="#cb8-20" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb8-21"><a href="#cb8-21" tabindex="-1"></a><span class="co">#&gt; This warning usually means that the model didn&#39;t converge in some cross-validation folds because it is predicting something close to a constant. As a result, certain performance metrics can&#39;t be calculated. This suggests that some of the hyperparameters chosen are doing very poorly.</span></span>
<span id="cb8-22"><a href="#cb8-22" tabindex="-1"></a><span class="co">#&gt; Training complete.</span></span></code></pre></div>
<p>You might have noticed that this one ran faster — that’s because we
reduced <code>kfold</code> and <code>cv_times</code>. This is okay for
testing things out and may even be necessary for smaller datasets. But
in general it may be better to have larger numbers for these parameters;
we think the defaults are a good starting point <span class="citation">(Topçuoğlu et al. 2020)</span>.</p>
<div id="custom-training-indices" class="section level3">
<h3>Custom training indices</h3>
<p>When <code>training_frac</code> is a fraction between 0 and 1, a
random sample of observations in the dataset are chosen for the training
set to satisfy the <code>training_frac</code> using
<code>get_partition_indices()</code>. However, in some cases you might
wish to control exactly which observations are in the training set. You
can instead assign <code>training_frac</code> a vector of indices that
correspond to which rows of the dataset should go in the training set
(all remaining sequences will go in the testing set). Here’s an example
with ~80% of the data in the training set:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>n_obs <span class="ot">&lt;-</span> otu_mini_bin <span class="sc">%&gt;%</span> <span class="fu">nrow</span>()</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>training_size <span class="ot">&lt;-</span> <span class="fl">0.8</span> <span class="sc">*</span> n_obs</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>training_rows <span class="ot">&lt;-</span> <span class="fu">sample</span>(n_obs, training_size)</span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>results_custom_train <span class="ot">&lt;-</span> <span class="fu">run_ml</span>(otu_mini_bin,</span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a>  <span class="st">&quot;glmnet&quot;</span>,</span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a>  <span class="at">kfold =</span> <span class="dv">2</span>,</span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a>  <span class="at">cv_times =</span> <span class="dv">5</span>,</span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a>  <span class="at">training_frac =</span> training_rows,</span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">2019</span></span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a>)</span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a><span class="co">#&gt; Using &#39;dx&#39; as the outcome column.</span></span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a><span class="co">#&gt; Using the custom training set indices provided by `training_frac`.</span></span>
<span id="cb9-13"><a href="#cb9-13" tabindex="-1"></a><span class="co">#&gt;       The fraction of data in the training set will be 0.8</span></span>
<span id="cb9-14"><a href="#cb9-14" tabindex="-1"></a><span class="co">#&gt; Training the model...</span></span>
<span id="cb9-15"><a href="#cb9-15" tabindex="-1"></a><span class="co">#&gt; Training complete.</span></span></code></pre></div>
</div>
</div>
<div id="changing-the-performance-metric" class="section level2">
<h2>Changing the performance metric</h2>
<p>There are two arguments that allow you to change what performance
metric to use for model evaluation, and what performance metrics to
calculate using the test data.</p>
<p><code>perf_metric_function</code> is the function used to calculate
the performance metrics.</p>
<p>The default for classification is
<code>caret::multiClassSummary()</code> and the default for regression
is <code>caret::defaultSummary()</code>. We’d suggest not changing this
unless you really know what you’re doing.</p>
<p><code>perf_metric_name</code> is the column name from the output of
<code>perf_metric_function</code>. We chose reasonable defaults (AUC for
binary, logLoss for multiclass, and RMSE for continuous), but the
default functions calculate a bunch of different performance metrics, so
you can choose a different one if you’d like.</p>
<p>The default performance metrics available for classification are:</p>
<pre><code>#&gt;  [1] &quot;logLoss&quot;                &quot;AUC&quot;                    &quot;prAUC&quot;                 
#&gt;  [4] &quot;Accuracy&quot;               &quot;Kappa&quot;                  &quot;Mean_F1&quot;               
#&gt;  [7] &quot;Mean_Sensitivity&quot;       &quot;Mean_Specificity&quot;       &quot;Mean_Pos_Pred_Value&quot;   
#&gt; [10] &quot;Mean_Neg_Pred_Value&quot;    &quot;Mean_Precision&quot;         &quot;Mean_Recall&quot;           
#&gt; [13] &quot;Mean_Detection_Rate&quot;    &quot;Mean_Balanced_Accuracy&quot;</code></pre>
<p>The default performance metrics available for regression are:</p>
<pre><code>#&gt; [1] &quot;RMSE&quot;     &quot;Rsquared&quot; &quot;MAE&quot;</code></pre>
<p>Here’s an example using prAUC instead of AUC:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a>results_pr <span class="ot">&lt;-</span> <span class="fu">run_ml</span>(otu_mini_bin,</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>  <span class="st">&quot;glmnet&quot;</span>,</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>  <span class="at">cv_times =</span> <span class="dv">5</span>,</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a>  <span class="at">perf_metric_name =</span> <span class="st">&quot;prAUC&quot;</span>,</span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">2019</span></span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a>)</span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a><span class="co">#&gt; Using &#39;dx&#39; as the outcome column.</span></span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a><span class="co">#&gt; Training the model...</span></span>
<span id="cb12-9"><a href="#cb12-9" tabindex="-1"></a><span class="co">#&gt; Warning in (function (w) : `caret::train()` issued the following warning:</span></span>
<span id="cb12-10"><a href="#cb12-10" tabindex="-1"></a><span class="co">#&gt;  </span></span>
<span id="cb12-11"><a href="#cb12-11" tabindex="-1"></a><span class="co">#&gt; simpleWarning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : There were missing values in resampled performance measures.</span></span>
<span id="cb12-12"><a href="#cb12-12" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb12-13"><a href="#cb12-13" tabindex="-1"></a><span class="co">#&gt; This warning usually means that the model didn&#39;t converge in some cross-validation folds because it is predicting something close to a constant. As a result, certain performance metrics can&#39;t be calculated. This suggests that some of the hyperparameters chosen are doing very poorly.</span></span>
<span id="cb12-14"><a href="#cb12-14" tabindex="-1"></a><span class="co">#&gt; Training complete.</span></span></code></pre></div>
<p>You’ll see that the cross-validation metric is prAUC, instead of the
default AUC:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a>results_pr<span class="sc">$</span>performance</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 × 17</span></span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a><span class="co">#&gt;   cv_metric_prAUC logLoss   AUC prAUC Accuracy  Kappa    F1 Sensitivity</span></span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a><span class="co">#&gt;             &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;</span></span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a><span class="co">#&gt; 1           0.577   0.691 0.663 0.605    0.538 0.0539 0.690           1</span></span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a><span class="co">#&gt; # ℹ 9 more variables: Specificity &lt;dbl&gt;, Pos_Pred_Value &lt;dbl&gt;,</span></span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a><span class="co">#&gt; #   Neg_Pred_Value &lt;dbl&gt;, Precision &lt;dbl&gt;, Recall &lt;dbl&gt;, Detection_Rate &lt;dbl&gt;,</span></span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a><span class="co">#&gt; #   Balanced_Accuracy &lt;dbl&gt;, method &lt;chr&gt;, seed &lt;dbl&gt;</span></span></code></pre></div>
</div>
<div id="using-groups" class="section level2">
<h2>Using groups</h2>
<p>The optional <code>groups</code> is a vector of groups to keep
together when splitting the data into train and test sets and for
cross-validation. Sometimes it’s important to split up the data based on
a grouping instead of just randomly. This allows you to control for
similarities within groups that you don’t want to skew your predictions
(i.e. batch effects). For example, with biological data you may have
samples collected from multiple hospitals, and you might like to keep
observations from the same hospital in the same partition.</p>
<p>Here’s an example where we split the data into train/test sets based
on groups:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="co"># make random groups</span></span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2019</span>)</span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a>grps <span class="ot">&lt;-</span> <span class="fu">sample</span>(LETTERS[<span class="dv">1</span><span class="sc">:</span><span class="dv">8</span>], <span class="fu">nrow</span>(otu_mini_bin), <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a>results_grp <span class="ot">&lt;-</span> <span class="fu">run_ml</span>(otu_mini_bin,</span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a>  <span class="st">&quot;glmnet&quot;</span>,</span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a>  <span class="at">cv_times =</span> <span class="dv">2</span>,</span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a>  <span class="at">training_frac =</span> <span class="fl">0.8</span>,</span>
<span id="cb14-8"><a href="#cb14-8" tabindex="-1"></a>  <span class="at">groups =</span> grps,</span>
<span id="cb14-9"><a href="#cb14-9" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">2019</span></span>
<span id="cb14-10"><a href="#cb14-10" tabindex="-1"></a>)</span>
<span id="cb14-11"><a href="#cb14-11" tabindex="-1"></a><span class="co">#&gt; Using &#39;dx&#39; as the outcome column.</span></span>
<span id="cb14-12"><a href="#cb14-12" tabindex="-1"></a><span class="co">#&gt; Fraction of data in the training set: 0.795 </span></span>
<span id="cb14-13"><a href="#cb14-13" tabindex="-1"></a><span class="co">#&gt;  Groups in the training set: A B D F G H </span></span>
<span id="cb14-14"><a href="#cb14-14" tabindex="-1"></a><span class="co">#&gt;  Groups in the testing set: C E</span></span>
<span id="cb14-15"><a href="#cb14-15" tabindex="-1"></a><span class="co">#&gt; Groups will be kept together in CV partitions</span></span>
<span id="cb14-16"><a href="#cb14-16" tabindex="-1"></a><span class="co">#&gt; Training the model...</span></span>
<span id="cb14-17"><a href="#cb14-17" tabindex="-1"></a><span class="co">#&gt; Training complete.</span></span></code></pre></div>
<p>The one difference here is <code>run_ml()</code> will report how much
of the data is in the training set if you run the above code chunk. This
can be a little finicky depending on how many samples and groups you
have. This is because it won’t be exactly what you specify with
<code>training_frac</code>, since you have to include all of one group
in either the training set <em>or</em> the test set.</p>
<div id="controlling-how-groups-are-assigned-to-partitions" class="section level3">
<h3>Controlling how groups are assigned to partitions</h3>
<p>When you use the <code>groups</code> parameter as above, by default
<code>run_ml()</code> will assume that you want all of the observations
from each group to be placed in the same partition of the train/test
split. This makes sense when you want to use groups to control for batch
effects. However, in some cases you might prefer to control exactly
which groups end up in which partition, and you might even be okay with
some observations from the same group being assigned to different
partitions.</p>
<p>For example, say you want groups A and B to be used for training, C
and D for testing, and you don’t have a preference for what happens to
the other groups. You can give the <code>group_partitions</code>
parameter a named list to specify which groups should go in the training
set and which should go in the testing set.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a>results_grp_part <span class="ot">&lt;-</span> <span class="fu">run_ml</span>(otu_mini_bin,</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a>  <span class="st">&quot;glmnet&quot;</span>,</span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a>  <span class="at">cv_times =</span> <span class="dv">2</span>,</span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a>  <span class="at">training_frac =</span> <span class="fl">0.8</span>,</span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a>  <span class="at">groups =</span> grps,</span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a>  <span class="at">group_partitions =</span> <span class="fu">list</span>(</span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a>    <span class="at">train =</span> <span class="fu">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>),</span>
<span id="cb15-8"><a href="#cb15-8" tabindex="-1"></a>    <span class="at">test =</span> <span class="fu">c</span>(<span class="st">&quot;C&quot;</span>, <span class="st">&quot;D&quot;</span>)</span>
<span id="cb15-9"><a href="#cb15-9" tabindex="-1"></a>  ),</span>
<span id="cb15-10"><a href="#cb15-10" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">2019</span></span>
<span id="cb15-11"><a href="#cb15-11" tabindex="-1"></a>)</span>
<span id="cb15-12"><a href="#cb15-12" tabindex="-1"></a><span class="co">#&gt; Using &#39;dx&#39; as the outcome column.</span></span>
<span id="cb15-13"><a href="#cb15-13" tabindex="-1"></a><span class="co">#&gt; Fraction of data in the training set: 0.785 </span></span>
<span id="cb15-14"><a href="#cb15-14" tabindex="-1"></a><span class="co">#&gt;  Groups in the training set: A B E F G H </span></span>
<span id="cb15-15"><a href="#cb15-15" tabindex="-1"></a><span class="co">#&gt;  Groups in the testing set: C D</span></span>
<span id="cb15-16"><a href="#cb15-16" tabindex="-1"></a><span class="co">#&gt; Groups will not be kept together in CV partitions because the number of groups in the training set is not larger than `kfold`</span></span>
<span id="cb15-17"><a href="#cb15-17" tabindex="-1"></a><span class="co">#&gt; Training the model...</span></span>
<span id="cb15-18"><a href="#cb15-18" tabindex="-1"></a><span class="co">#&gt; Training complete.</span></span></code></pre></div>
<p>In the above case, all observations from A &amp; B will be used for
training, all from C &amp; D will be used for testing, and the remaining
groups will be randomly assigned to one or the other to satisfy the
<code>training_frac</code> as closely as possible.</p>
<p>In another scenario, maybe you want only groups A through F to be
used for training, but you also want to allow other observations not
selected for training from A through F to be used for testing:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a>results_grp_trainA <span class="ot">&lt;-</span> <span class="fu">run_ml</span>(otu_mini_bin,</span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a>  <span class="st">&quot;glmnet&quot;</span>,</span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a>  <span class="at">cv_times =</span> <span class="dv">2</span>,</span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a>  <span class="at">kfold =</span> <span class="dv">2</span>,</span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a>  <span class="at">training_frac =</span> <span class="fl">0.5</span>,</span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a>  <span class="at">groups =</span> grps,</span>
<span id="cb16-7"><a href="#cb16-7" tabindex="-1"></a>  <span class="at">group_partitions =</span> <span class="fu">list</span>(</span>
<span id="cb16-8"><a href="#cb16-8" tabindex="-1"></a>    <span class="at">train =</span> <span class="fu">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;C&quot;</span>, <span class="st">&quot;D&quot;</span>, <span class="st">&quot;E&quot;</span>, <span class="st">&quot;F&quot;</span>),</span>
<span id="cb16-9"><a href="#cb16-9" tabindex="-1"></a>    <span class="at">test =</span> <span class="fu">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;C&quot;</span>, <span class="st">&quot;D&quot;</span>, <span class="st">&quot;E&quot;</span>, <span class="st">&quot;F&quot;</span>, <span class="st">&quot;G&quot;</span>, <span class="st">&quot;H&quot;</span>)</span>
<span id="cb16-10"><a href="#cb16-10" tabindex="-1"></a>  ),</span>
<span id="cb16-11"><a href="#cb16-11" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">2019</span></span>
<span id="cb16-12"><a href="#cb16-12" tabindex="-1"></a>)</span>
<span id="cb16-13"><a href="#cb16-13" tabindex="-1"></a><span class="co">#&gt; Using &#39;dx&#39; as the outcome column.</span></span>
<span id="cb16-14"><a href="#cb16-14" tabindex="-1"></a><span class="co">#&gt; Fraction of data in the training set: 0.5 </span></span>
<span id="cb16-15"><a href="#cb16-15" tabindex="-1"></a><span class="co">#&gt;  Groups in the training set: A B C D E F </span></span>
<span id="cb16-16"><a href="#cb16-16" tabindex="-1"></a><span class="co">#&gt;  Groups in the testing set: A B C D E F G H</span></span>
<span id="cb16-17"><a href="#cb16-17" tabindex="-1"></a><span class="co">#&gt; Groups will be kept together in CV partitions</span></span>
<span id="cb16-18"><a href="#cb16-18" tabindex="-1"></a><span class="co">#&gt; Training the model...</span></span>
<span id="cb16-19"><a href="#cb16-19" tabindex="-1"></a><span class="co">#&gt; Training complete.</span></span></code></pre></div>
<p>If you need even more control than this, take a look at <a href="#custom-training-indices">setting custom training indices</a>. You
might also prefer to provide your own train control scheme with the
<code>cross_val</code> parameter in <code>run_ml()</code>.</p>
</div>
</div>
<div id="more-arguments" class="section level2">
<h2>More arguments</h2>
<p>Some ML methods take optional arguments, such as <code>ntree</code>
for <code>randomForest</code>-based models or <a href="https://topepo.github.io/caret/train-models-by-tag.html#Accepts_Case_Weights">case
weights</a>. Any additional arguments you give to <code>run_ml()</code>
are forwarded along to <code>caret::train()</code> so you can leverage
those options.</p>
<div id="case-weights" class="section level3">
<h3>Case weights</h3>
<p>If you want to use case weights, you will also need to use custom
indices for the training data (i.e. perform the partition before
<code>run_ml(</code>) as <a href="#custom-training-indices">above</a>).
Here’s one way to do this with the weights calculated from the
proportion of each class in the data set, with ~70% of the data in the
training set:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">20221016</span>)</span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a>train_set_indices <span class="ot">&lt;-</span> <span class="fu">get_partition_indices</span>(otu_mini_bin <span class="sc">%&gt;%</span> <span class="fu">pull</span>(dx),</span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a>  <span class="at">training_frac =</span> <span class="fl">0.70</span></span>
<span id="cb17-5"><a href="#cb17-5" tabindex="-1"></a>)</span>
<span id="cb17-6"><a href="#cb17-6" tabindex="-1"></a>case_weights_dat <span class="ot">&lt;-</span> otu_mini_bin <span class="sc">%&gt;%</span></span>
<span id="cb17-7"><a href="#cb17-7" tabindex="-1"></a>  <span class="fu">count</span>(dx) <span class="sc">%&gt;%</span></span>
<span id="cb17-8"><a href="#cb17-8" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">p =</span> n <span class="sc">/</span> <span class="fu">sum</span>(n)) <span class="sc">%&gt;%</span></span>
<span id="cb17-9"><a href="#cb17-9" tabindex="-1"></a>  <span class="fu">select</span>(dx, p) <span class="sc">%&gt;%</span></span>
<span id="cb17-10"><a href="#cb17-10" tabindex="-1"></a>  <span class="fu">right_join</span>(otu_mini_bin, <span class="at">by =</span> <span class="st">&quot;dx&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb17-11"><a href="#cb17-11" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span><span class="fu">starts_with</span>(<span class="st">&quot;Otu&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb17-12"><a href="#cb17-12" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb17-13"><a href="#cb17-13" tabindex="-1"></a>    <span class="at">row_num =</span> <span class="fu">row_number</span>(),</span>
<span id="cb17-14"><a href="#cb17-14" tabindex="-1"></a>    <span class="at">in_train =</span> row_num <span class="sc">%in%</span> train_set_indices</span>
<span id="cb17-15"><a href="#cb17-15" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb17-16"><a href="#cb17-16" tabindex="-1"></a>  <span class="fu">filter</span>(in_train)</span>
<span id="cb17-17"><a href="#cb17-17" tabindex="-1"></a><span class="fu">head</span>(case_weights_dat)</span>
<span id="cb17-18"><a href="#cb17-18" tabindex="-1"></a><span class="co">#&gt;       dx    p row_num in_train</span></span>
<span id="cb17-19"><a href="#cb17-19" tabindex="-1"></a><span class="co">#&gt; 1 cancer 0.49       1     TRUE</span></span>
<span id="cb17-20"><a href="#cb17-20" tabindex="-1"></a><span class="co">#&gt; 2 cancer 0.49       2     TRUE</span></span>
<span id="cb17-21"><a href="#cb17-21" tabindex="-1"></a><span class="co">#&gt; 3 cancer 0.49       3     TRUE</span></span>
<span id="cb17-22"><a href="#cb17-22" tabindex="-1"></a><span class="co">#&gt; 4 cancer 0.49       4     TRUE</span></span>
<span id="cb17-23"><a href="#cb17-23" tabindex="-1"></a><span class="co">#&gt; 5 cancer 0.49       5     TRUE</span></span>
<span id="cb17-24"><a href="#cb17-24" tabindex="-1"></a><span class="co">#&gt; 6 cancer 0.49       6     TRUE</span></span>
<span id="cb17-25"><a href="#cb17-25" tabindex="-1"></a><span class="fu">tail</span>(case_weights_dat)</span>
<span id="cb17-26"><a href="#cb17-26" tabindex="-1"></a><span class="co">#&gt;         dx    p row_num in_train</span></span>
<span id="cb17-27"><a href="#cb17-27" tabindex="-1"></a><span class="co">#&gt; 136 normal 0.51     194     TRUE</span></span>
<span id="cb17-28"><a href="#cb17-28" tabindex="-1"></a><span class="co">#&gt; 137 normal 0.51     195     TRUE</span></span>
<span id="cb17-29"><a href="#cb17-29" tabindex="-1"></a><span class="co">#&gt; 138 normal 0.51     196     TRUE</span></span>
<span id="cb17-30"><a href="#cb17-30" tabindex="-1"></a><span class="co">#&gt; 139 normal 0.51     197     TRUE</span></span>
<span id="cb17-31"><a href="#cb17-31" tabindex="-1"></a><span class="co">#&gt; 140 normal 0.51     198     TRUE</span></span>
<span id="cb17-32"><a href="#cb17-32" tabindex="-1"></a><span class="co">#&gt; 141 normal 0.51     200     TRUE</span></span>
<span id="cb17-33"><a href="#cb17-33" tabindex="-1"></a><span class="fu">nrow</span>(case_weights_dat) <span class="sc">/</span> <span class="fu">nrow</span>(otu_mini_bin)</span>
<span id="cb17-34"><a href="#cb17-34" tabindex="-1"></a><span class="co">#&gt; [1] 0.705</span></span></code></pre></div>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a>results_weighted <span class="ot">&lt;-</span> <span class="fu">run_ml</span>(otu_mini_bin,</span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a>  <span class="st">&quot;glmnet&quot;</span>,</span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a>  <span class="at">outcome_colname =</span> <span class="st">&quot;dx&quot;</span>,</span>
<span id="cb18-4"><a href="#cb18-4" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">2019</span>,</span>
<span id="cb18-5"><a href="#cb18-5" tabindex="-1"></a>  <span class="at">training_frac =</span> case_weights_dat <span class="sc">%&gt;%</span> <span class="fu">pull</span>(row_num),</span>
<span id="cb18-6"><a href="#cb18-6" tabindex="-1"></a>  <span class="at">weights =</span> case_weights_dat <span class="sc">%&gt;%</span> <span class="fu">pull</span>(p)</span>
<span id="cb18-7"><a href="#cb18-7" tabindex="-1"></a>)</span></code></pre></div>
<p>See the caret docs for <a href="https://topepo.github.io/caret/train-models-by-tag.html#Accepts_Case_Weights">a
list of models that accept case weights</a>.</p>
</div>
</div>
</div>
<div id="finding-feature-importance" class="section level1">
<h1>Finding feature importance</h1>
<p>To find which features are contributing to predictive power, you can
use <code>find_feature_importance = TRUE</code>. How we use permutation
importance to determine feature importance is described in <span class="citation">(Topçuoğlu et al. 2020)</span>. Briefly, it permutes
each of the features individually (or correlated ones together) and
evaluates how much the performance metric decreases. The more
performance decreases when the feature is randomly shuffled, the more
important that feature is. The default is <code>FALSE</code> because it
takes a while to run and is only useful if you want to know what
features are important in predicting your outcome.</p>
<p>Let’s look at some feature importance results:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a>results_imp <span class="ot">&lt;-</span> <span class="fu">run_ml</span>(otu_mini_bin,</span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a>  <span class="st">&quot;rf&quot;</span>,</span>
<span id="cb19-3"><a href="#cb19-3" tabindex="-1"></a>  <span class="at">outcome_colname =</span> <span class="st">&quot;dx&quot;</span>,</span>
<span id="cb19-4"><a href="#cb19-4" tabindex="-1"></a>  <span class="at">find_feature_importance =</span> <span class="cn">TRUE</span>,</span>
<span id="cb19-5"><a href="#cb19-5" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">2019</span></span>
<span id="cb19-6"><a href="#cb19-6" tabindex="-1"></a>)</span></code></pre></div>
<p>Now, we can check out the feature importances:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a>results_imp<span class="sc">$</span>feature_importance</span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a><span class="co">#&gt;    perf_metric perf_metric_diff     pvalue   lower   upper     feat method</span></span>
<span id="cb20-3"><a href="#cb20-3" tabindex="-1"></a><span class="co">#&gt; 1    0.5459125        0.0003375 0.51485149 0.49125 0.60250 Otu00001     rf</span></span>
<span id="cb20-4"><a href="#cb20-4" tabindex="-1"></a><span class="co">#&gt; 2    0.5682625       -0.0220125 0.73267327 0.50625 0.63125 Otu00002     rf</span></span>
<span id="cb20-5"><a href="#cb20-5" tabindex="-1"></a><span class="co">#&gt; 3    0.5482875       -0.0020375 0.56435644 0.50500 0.59000 Otu00003     rf</span></span>
<span id="cb20-6"><a href="#cb20-6" tabindex="-1"></a><span class="co">#&gt; 4    0.6314375       -0.0851875 1.00000000 0.55250 0.71250 Otu00004     rf</span></span>
<span id="cb20-7"><a href="#cb20-7" tabindex="-1"></a><span class="co">#&gt; 5    0.4991750        0.0470750 0.08910891 0.44125 0.57125 Otu00005     rf</span></span>
<span id="cb20-8"><a href="#cb20-8" tabindex="-1"></a><span class="co">#&gt; 6    0.5364875        0.0097625 0.28712871 0.50125 0.57375 Otu00006     rf</span></span>
<span id="cb20-9"><a href="#cb20-9" tabindex="-1"></a><span class="co">#&gt; 7    0.5382875        0.0079625 0.39603960 0.47500 0.58750 Otu00007     rf</span></span>
<span id="cb20-10"><a href="#cb20-10" tabindex="-1"></a><span class="co">#&gt; 8    0.5160500        0.0302000 0.09900990 0.46750 0.55750 Otu00008     rf</span></span>
<span id="cb20-11"><a href="#cb20-11" tabindex="-1"></a><span class="co">#&gt; 9    0.5293375        0.0169125 0.17821782 0.49500 0.55625 Otu00009     rf</span></span>
<span id="cb20-12"><a href="#cb20-12" tabindex="-1"></a><span class="co">#&gt; 10   0.4976500        0.0486000 0.12871287 0.41000 0.56250 Otu00010     rf</span></span>
<span id="cb20-13"><a href="#cb20-13" tabindex="-1"></a><span class="co">#&gt;    perf_metric_name seed</span></span>
<span id="cb20-14"><a href="#cb20-14" tabindex="-1"></a><span class="co">#&gt; 1               AUC 2019</span></span>
<span id="cb20-15"><a href="#cb20-15" tabindex="-1"></a><span class="co">#&gt; 2               AUC 2019</span></span>
<span id="cb20-16"><a href="#cb20-16" tabindex="-1"></a><span class="co">#&gt; 3               AUC 2019</span></span>
<span id="cb20-17"><a href="#cb20-17" tabindex="-1"></a><span class="co">#&gt; 4               AUC 2019</span></span>
<span id="cb20-18"><a href="#cb20-18" tabindex="-1"></a><span class="co">#&gt; 5               AUC 2019</span></span>
<span id="cb20-19"><a href="#cb20-19" tabindex="-1"></a><span class="co">#&gt; 6               AUC 2019</span></span>
<span id="cb20-20"><a href="#cb20-20" tabindex="-1"></a><span class="co">#&gt; 7               AUC 2019</span></span>
<span id="cb20-21"><a href="#cb20-21" tabindex="-1"></a><span class="co">#&gt; 8               AUC 2019</span></span>
<span id="cb20-22"><a href="#cb20-22" tabindex="-1"></a><span class="co">#&gt; 9               AUC 2019</span></span>
<span id="cb20-23"><a href="#cb20-23" tabindex="-1"></a><span class="co">#&gt; 10              AUC 2019</span></span></code></pre></div>
<p>There are several columns:</p>
<ol style="list-style-type: decimal">
<li><code>perf_metric</code>: The performance value of the permuted
feature.</li>
<li><code>perf_metric_diff</code>: The difference between the
performance for the actual and permuted data (i.e. test performance
minus permuted performance). Features with a larger
<code>perf_metric_diff</code> are more important.</li>
<li><code>pvalue</code>: the probability of obtaining the actual
performance value under the null hypothesis.</li>
<li><code>lower</code>: the lower bound for the 95% confidence interval
of <code>perf_metric</code>.</li>
<li><code>upper</code>: the upper bound for the 95% confidence interval
of <code>perf_metric</code>.</li>
<li><code>feat</code>: The feature (or group of correlated features)
that was permuted.</li>
<li><code>method</code>: The <a href="#the-methods-we-support">ML
method</a> used.</li>
<li><code>perf_metric_name</code>: The <a href="#id_-changing-the-performance-metric">name of the performance
metric</a> represented by <code>perf_metric</code> &amp;
<code>perf_metric_diff</code>.</li>
<li><code>seed</code>: The seed (if set).</li>
</ol>
<p>As you can see here, the differences are negligible (close to zero),
which makes sense since our model isn’t great. If you’re interested in
feature importance, it’s especially useful to run multiple different
train/test splits, as shown in our <a href="https://github.com/SchlossLab/mikropml-snakemake-workflow/">example
snakemake workflow</a>.</p>
<p>You can also choose to permute correlated features together using
<code>corr_thresh</code> (default: 1). Any features that are above the
correlation threshold are permuted together; i.e. perfectly correlated
features are permuted together when using the default value.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a>results_imp_corr <span class="ot">&lt;-</span> <span class="fu">run_ml</span>(otu_mini_bin,</span>
<span id="cb21-2"><a href="#cb21-2" tabindex="-1"></a>  <span class="st">&quot;glmnet&quot;</span>,</span>
<span id="cb21-3"><a href="#cb21-3" tabindex="-1"></a>  <span class="at">cv_times =</span> <span class="dv">5</span>,</span>
<span id="cb21-4"><a href="#cb21-4" tabindex="-1"></a>  <span class="at">find_feature_importance =</span> <span class="cn">TRUE</span>,</span>
<span id="cb21-5"><a href="#cb21-5" tabindex="-1"></a>  <span class="at">corr_thresh =</span> <span class="fl">0.2</span>,</span>
<span id="cb21-6"><a href="#cb21-6" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">2019</span></span>
<span id="cb21-7"><a href="#cb21-7" tabindex="-1"></a>)</span>
<span id="cb21-8"><a href="#cb21-8" tabindex="-1"></a><span class="co">#&gt; Using &#39;dx&#39; as the outcome column.</span></span>
<span id="cb21-9"><a href="#cb21-9" tabindex="-1"></a><span class="co">#&gt; Training the model...</span></span>
<span id="cb21-10"><a href="#cb21-10" tabindex="-1"></a><span class="co">#&gt; Warning in (function (w) : `caret::train()` issued the following warning:</span></span>
<span id="cb21-11"><a href="#cb21-11" tabindex="-1"></a><span class="co">#&gt;  </span></span>
<span id="cb21-12"><a href="#cb21-12" tabindex="-1"></a><span class="co">#&gt; simpleWarning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : There were missing values in resampled performance measures.</span></span>
<span id="cb21-13"><a href="#cb21-13" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb21-14"><a href="#cb21-14" tabindex="-1"></a><span class="co">#&gt; This warning usually means that the model didn&#39;t converge in some cross-validation folds because it is predicting something close to a constant. As a result, certain performance metrics can&#39;t be calculated. This suggests that some of the hyperparameters chosen are doing very poorly.</span></span>
<span id="cb21-15"><a href="#cb21-15" tabindex="-1"></a><span class="co">#&gt; Training complete.</span></span>
<span id="cb21-16"><a href="#cb21-16" tabindex="-1"></a><span class="co">#&gt; Finding feature importance...</span></span>
<span id="cb21-17"><a href="#cb21-17" tabindex="-1"></a><span class="co">#&gt; Feature importance complete.</span></span>
<span id="cb21-18"><a href="#cb21-18" tabindex="-1"></a>results_imp_corr<span class="sc">$</span>feature_importance</span>
<span id="cb21-19"><a href="#cb21-19" tabindex="-1"></a><span class="co">#&gt;   perf_metric perf_metric_diff     pvalue     lower     upper</span></span>
<span id="cb21-20"><a href="#cb21-20" tabindex="-1"></a><span class="co">#&gt; 1   0.4941842        0.1531842 0.05940594 0.3236842 0.6473684</span></span>
<span id="cb21-21"><a href="#cb21-21" tabindex="-1"></a><span class="co">#&gt;                                                                                        feat</span></span>
<span id="cb21-22"><a href="#cb21-22" tabindex="-1"></a><span class="co">#&gt; 1 Otu00001|Otu00002|Otu00003|Otu00004|Otu00005|Otu00006|Otu00007|Otu00008|Otu00009|Otu00010</span></span>
<span id="cb21-23"><a href="#cb21-23" tabindex="-1"></a><span class="co">#&gt;   method perf_metric_name seed</span></span>
<span id="cb21-24"><a href="#cb21-24" tabindex="-1"></a><span class="co">#&gt; 1 glmnet              AUC 2019</span></span></code></pre></div>
<p>You can see which features were permuted together in the
<code>feat</code> column. Here all 3 features were permuted together
(which doesn’t really make sense, but it’s just an example).</p>
<p>If you previously executed <code>run_ml()</code> without feature
importance but now wish to find feature importance after the fact, see
the example code in the <code>get_feature_importance()</code>
documentation.</p>
<p><code>get_feature_importance()</code> can show a live progress bar,
see <code>vignette(&quot;parallel&quot;)</code> for examples.</p>
</div>
<div id="tuning-hyperparameters-using-the-hyperparameter-argument" class="section level1">
<h1>Tuning hyperparameters (using the <code>hyperparameter</code>
argument)</h1>
<p>This is important, so we have a whole vignette about them. The bottom
line is we provide default hyperparameters that you can start with, but
it’s important to tune your hyperparameters. For more information about
what the default hyperparameters are, and how to tune hyperparameters,
see <code>vignette(&quot;tuning&quot;)</code>.</p>
</div>
<div id="other-models" class="section level1">
<h1>Other models</h1>
<p>Here are examples of how to train and evaluate other models. The
output for all of them is very similar, so we won’t go into those
details.</p>
<div id="random-forest" class="section level2">
<h2>Random forest</h2>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a>results_rf <span class="ot">&lt;-</span> <span class="fu">run_ml</span>(otu_mini_bin,</span>
<span id="cb22-2"><a href="#cb22-2" tabindex="-1"></a>  <span class="st">&quot;rf&quot;</span>,</span>
<span id="cb22-3"><a href="#cb22-3" tabindex="-1"></a>  <span class="at">cv_times =</span> <span class="dv">5</span>,</span>
<span id="cb22-4"><a href="#cb22-4" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">2019</span></span>
<span id="cb22-5"><a href="#cb22-5" tabindex="-1"></a>)</span></code></pre></div>
<p>The <code>rf</code> engine takes an optional argument
<code>ntree</code>: the number of trees to use for random forest. This
can’t be tuned using the <code>rf</code> package implementation of
random forest. Please refer to <code>caret</code> documentation if you
are interested in other packages with random forest implementations.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a>results_rf_nt <span class="ot">&lt;-</span> <span class="fu">run_ml</span>(otu_mini_bin,</span>
<span id="cb23-2"><a href="#cb23-2" tabindex="-1"></a>  <span class="st">&quot;rf&quot;</span>,</span>
<span id="cb23-3"><a href="#cb23-3" tabindex="-1"></a>  <span class="at">cv_times =</span> <span class="dv">5</span>,</span>
<span id="cb23-4"><a href="#cb23-4" tabindex="-1"></a>  <span class="at">ntree =</span> <span class="dv">1000</span>,</span>
<span id="cb23-5"><a href="#cb23-5" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">2019</span></span>
<span id="cb23-6"><a href="#cb23-6" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div id="decision-tree" class="section level2">
<h2>Decision tree</h2>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" tabindex="-1"></a>results_dt <span class="ot">&lt;-</span> <span class="fu">run_ml</span>(otu_mini_bin,</span>
<span id="cb24-2"><a href="#cb24-2" tabindex="-1"></a>  <span class="st">&quot;rpart2&quot;</span>,</span>
<span id="cb24-3"><a href="#cb24-3" tabindex="-1"></a>  <span class="at">cv_times =</span> <span class="dv">5</span>,</span>
<span id="cb24-4"><a href="#cb24-4" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">2019</span></span>
<span id="cb24-5"><a href="#cb24-5" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div id="svm" class="section level2">
<h2>SVM</h2>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" tabindex="-1"></a>results_svm <span class="ot">&lt;-</span> <span class="fu">run_ml</span>(otu_mini_bin,</span>
<span id="cb25-2"><a href="#cb25-2" tabindex="-1"></a>  <span class="st">&quot;svmRadial&quot;</span>,</span>
<span id="cb25-3"><a href="#cb25-3" tabindex="-1"></a>  <span class="at">cv_times =</span> <span class="dv">5</span>,</span>
<span id="cb25-4"><a href="#cb25-4" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">2019</span></span>
<span id="cb25-5"><a href="#cb25-5" tabindex="-1"></a>)</span></code></pre></div>
<p>If you get a message “maximum number of iterations reached”, see <a href="https://github.com/topepo/caret/issues/425">this issue</a> in
caret.</p>
</div>
</div>
<div id="other-data" class="section level1">
<h1>Other data</h1>
<div id="multiclass-data" class="section level2">
<h2>Multiclass data</h2>
<p>We provide <code>otu_mini_multi</code> with a multiclass outcome
(three or more outcomes):</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" tabindex="-1"></a>otu_mini_multi <span class="sc">%&gt;%</span></span>
<span id="cb26-2"><a href="#cb26-2" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">pull</span>(<span class="st">&quot;dx&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb26-3"><a href="#cb26-3" tabindex="-1"></a>  <span class="fu">unique</span>()</span>
<span id="cb26-4"><a href="#cb26-4" tabindex="-1"></a><span class="co">#&gt; [1] &quot;adenoma&quot;   &quot;carcinoma&quot; &quot;normal&quot;</span></span></code></pre></div>
<p>Here’s an example of running multiclass data:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" tabindex="-1"></a>results_multi <span class="ot">&lt;-</span> <span class="fu">run_ml</span>(otu_mini_multi,</span>
<span id="cb27-2"><a href="#cb27-2" tabindex="-1"></a>  <span class="at">outcome_colname =</span> <span class="st">&quot;dx&quot;</span>,</span>
<span id="cb27-3"><a href="#cb27-3" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">2019</span></span>
<span id="cb27-4"><a href="#cb27-4" tabindex="-1"></a>)</span></code></pre></div>
<p>The performance metrics are slightly different, but the format of
everything else is the same:</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" tabindex="-1"></a>results_multi<span class="sc">$</span>performance</span>
<span id="cb28-2"><a href="#cb28-2" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 × 17</span></span>
<span id="cb28-3"><a href="#cb28-3" tabindex="-1"></a><span class="co">#&gt;   cv_metric_logLoss logLoss   AUC prAUC Accuracy  Kappa Mean_F1 Mean_Sensitivity</span></span>
<span id="cb28-4"><a href="#cb28-4" tabindex="-1"></a><span class="co">#&gt;               &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;              &lt;dbl&gt;</span></span>
<span id="cb28-5"><a href="#cb28-5" tabindex="-1"></a><span class="co">#&gt; 1              1.07    1.11 0.506 0.353    0.382 0.0449 &lt;NA&gt;               0.360</span></span>
<span id="cb28-6"><a href="#cb28-6" tabindex="-1"></a><span class="co">#&gt; # ℹ 9 more variables: Mean_Specificity &lt;dbl&gt;, Mean_Pos_Pred_Value &lt;chr&gt;,</span></span>
<span id="cb28-7"><a href="#cb28-7" tabindex="-1"></a><span class="co">#&gt; #   Mean_Neg_Pred_Value &lt;dbl&gt;, Mean_Precision &lt;chr&gt;, Mean_Recall &lt;dbl&gt;,</span></span>
<span id="cb28-8"><a href="#cb28-8" tabindex="-1"></a><span class="co">#&gt; #   Mean_Detection_Rate &lt;dbl&gt;, Mean_Balanced_Accuracy &lt;dbl&gt;, method &lt;chr&gt;,</span></span>
<span id="cb28-9"><a href="#cb28-9" tabindex="-1"></a><span class="co">#&gt; #   seed &lt;dbl&gt;</span></span></code></pre></div>
</div>
<div id="continuous-data" class="section level2">
<h2>Continuous data</h2>
<p>And here’s an example for running continuous data, where the outcome
column is numerical:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" tabindex="-1"></a>results_cont <span class="ot">&lt;-</span> <span class="fu">run_ml</span>(otu_mini_bin[, <span class="dv">2</span><span class="sc">:</span><span class="dv">11</span>],</span>
<span id="cb29-2"><a href="#cb29-2" tabindex="-1"></a>  <span class="st">&quot;glmnet&quot;</span>,</span>
<span id="cb29-3"><a href="#cb29-3" tabindex="-1"></a>  <span class="at">outcome_colname =</span> <span class="st">&quot;Otu00001&quot;</span>,</span>
<span id="cb29-4"><a href="#cb29-4" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">2019</span></span>
<span id="cb29-5"><a href="#cb29-5" tabindex="-1"></a>)</span></code></pre></div>
<p>Again, the performance metrics are slightly different, but the format
of the rest is the same:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" tabindex="-1"></a>results_cont<span class="sc">$</span>performance</span>
<span id="cb30-2"><a href="#cb30-2" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 × 6</span></span>
<span id="cb30-3"><a href="#cb30-3" tabindex="-1"></a><span class="co">#&gt;   cv_metric_RMSE  RMSE Rsquared   MAE method  seed</span></span>
<span id="cb30-4"><a href="#cb30-4" tabindex="-1"></a><span class="co">#&gt;            &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;</span></span>
<span id="cb30-5"><a href="#cb30-5" tabindex="-1"></a><span class="co">#&gt; 1           622.  731.   0.0893  472. glmnet  2019</span></span></code></pre></div>
</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-tang_democratizing_2020" class="csl-entry">
Tang, Shengpu, Parmida Davarmanesh, Yanmeng Song, Danai Koutra, Michael
W. Sjoding, and Jenna Wiens. 2020. <span>“Democratizing <span>EHR</span>
Analyses with <span>FIDDLE</span>: A Flexible Data-Driven Preprocessing
Pipeline for Structured Clinical Data.”</span> <em>J Am Med Inform
Assoc</em>, October. <a href="https://doi.org/10.1093/jamia/ocaa139">https://doi.org/10.1093/jamia/ocaa139</a>.
</div>
<div id="ref-topcuoglu_framework_2020" class="csl-entry">
Topçuoğlu, Begüm D., Nicholas A. Lesniak, Mack T. Ruffin, Jenna Wiens,
and Patrick D. Schloss. 2020. <span>“A <span>Framework</span> for
<span>Effective Application</span> of <span>Machine Learning</span> to
<span>Microbiome</span>-<span>Based Classification
Problems</span>.”</span> <em>mBio</em> 11 (3). <a href="https://doi.org/10.1128/mBio.00434-20">https://doi.org/10.1128/mBio.00434-20</a>.
</div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
